y = data['class']
x, x_test, y, y_test = train_test_split(x,y, stratify=y, test_size=0.10, random_state=42)
# Vectorize text reviews to numbers
vec = CountVectorizer()
x = vec.fit_transform(x).toarray()
x_test = vec.transform(x_test).toarray()
from sklearn.naive_bayes import BernoulliNB
model = BernoulliNB()
model.fit(x, y)
# score test data test
model.score(x_test, y_test)
# score for data training
model.score(x,y)
from jcopml.plot import plot_confusion_matrix
plot_confusion_matrix(x,y,x_test,y_test,model)
model.predict(vec.transform(['kalian brengsek']))
from jcopml.plot import plot_classification_report
plot_classification_report(x,y,x_test,y_test,model, report = True)
reticulate::repl_python()
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import confusion_matrix, accuracy_score
data = pd.read_csv("C:\\Users\\fkhas\\Documents\\Projects\\Twitter\\SA\\analisissentimen\\Datasets\\Sentiment Idul Fitri.csv")
data.head(10)
def preprocess_data(data):
# Remove package name as it's not relevant
data = data.drop('score', axis=1)
# Convert text to lowercase
data['text'] = data['text'].str.strip().str.lower()
return data
data = preprocess_data(data)
# Split into training and testing data
x = data['text']
y = data['class']
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import confusion_matrix, accuracy_score
data = pd.read_csv("C:\\Users\\fkhas\\Documents\\Projects\\Twitter\\SA\\analisissentimen\\Datasets\\Sentiment Idul Fitri.csv")
data.head(10)
def preprocess_data(data):
# Remove package name as it's not relevant
data = data.drop('score', axis=1)
# Convert text to lowercase
data['text'] = data['text'].str.strip().str.lower()
return data
data = preprocess_data(data)
# Split into training and testing data
x = data['text']
y = data['class']
cv = CountVectorizer()
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state=42)
x = cv.fit_transform(x_train).toarray()
x_test = cv.transform(x_test).toarray()
x_test
x_test[0]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state=42)
x_train = cv.fit_transform(x_train).toarray()
x_test = cv.transform(x_test).toarray()
y_train = cv.fit_transform(y_train).toarray()
y_test = cv.transform(y_test).toarray()
x_train, x_test, y_train, y_test = train_test_split(x, y, stratify = y,test_size = 0.1, random_state=42)
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import confusion_matrix, accuracy_score
data = pd.read_csv("C:\\Users\\fkhas\\Documents\\Projects\\Twitter\\SA\\analisissentimen\\Datasets\\Sentiment Idul Fitri.csv")
data.head(10)
def preprocess_data(data):
# Remove package name as it's not relevant
data = data.drop('score', axis=1)
# Convert text to lowercase
data['text'] = data['text'].str.strip().str.lower()
return data
data = preprocess_data(data)
# Split into training and testing data
x = data['text']
y = data['class']
cv = CountVectorizer()
x_train, x_test, y_train, y_test = train_test_split(x, y, stratify = y,test_size = 0.1, random_state=42)
x_train = cv.fit_transform(x_train).toarray()
x_test = cv.transform(x_test).toarray()
y_train = cv.fit_transform(y_train).toarray()
y_test = cv.transform(y_test).toarray()
from sklearn.naive_bayes import BernoulliNB
model = BernoulliNB()
model.fit(x_train, y_train)
model = BernoulliNB()
model.fit(x_train, y_train)
model.fit(x_test, y_test)
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import confusion_matrix, accuracy_score
data = pd.read_csv("C:\\Users\\fkhas\\Documents\\Projects\\Twitter\\SA\\analisissentimen\\Datasets\\Sentiment Idul Fitri.csv")
data.head(10)
def preprocess_data(data):
# Remove package name as it's not relevant
data = data.drop('score', axis=1)
# Convert text to lowercase
data['text'] = data['text'].str.strip().str.lower()
return data
data = preprocess_data(data)
# Split into training and testing data
x = data['text']
y = data['class']
cv = CountVectorizer()
x_train, x_test, y_train, y_test = train_test_split(x, y, stratify = y,test_size = 0.1, random_state=42)
x_train = cv.fit_transform(x_train).toarray()
x_test = cv.transform(x_test).toarray()
from sklearn.naive_bayes import BernoulliNB
model = BernoulliNB()
model.fit(x_test, y_test)
model.score(x_train,y_train)
model.score(x_test, y_test)
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import confusion_matrix, accuracy_score
data = pd.read_csv("C:\\Users\\fkhas\\Documents\\Projects\\Twitter\\SA\\analisissentimen\\Datasets\\Sentiment Idul Fitri.csv")
data.head(10)
def preprocess_data(data):
# Remove package name as it's not relevant
data = data.drop('score', axis=1)
# Convert text to lowercase
data['text'] = data['text'].str.strip().str.lower()
return data
data = preprocess_data(data)
# Split into training and testing data
x = data['text']
y = data['class']
x, x_test, y, y_test = train_test_split(x,y, stratify=y, test_size=0.10, random_state=42)
# Vectorize text reviews to numbers
vec = CountVectorizer()
x = vec.fit_transform(x).toarray()
x_test = vec.transform(x_test).toarray()
from sklearn.naive_bayes import BernoulliNB
model = BernoulliNB()
model.fit(x, y)
# score test data test
model.score(x_test, y_test)
# score for data training
model.score(x,y)
from jcopml.plot import plot_confusion_matrix
plot_confusion_matrix(x,y,x_test,y_test,model)
model.predict(vec.transform(['kalian brengsek']))
from jcopml.plot import plot_classification_report
plot_classification_report(x,y,x_test,y_test,model, report = True)
reticulate::repl_python()
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import confusion_matrix, accuracy_score
data = pd.read_csv("C:\\Users\\fkhas\\Documents\\Projects\\Twitter\\SA\\analisissentimen\\Datasets\\Sentiment Idul Fitri.csv")
data.head(10)
def preprocess_data(data):
# Remove package name as it's not relevant
data = data.drop('score', axis=1)
# Convert text to lowercase
data['text'] = data['text'].str.strip().str.lower()
return data
data = preprocess_data(data)
# Split into training and testing data
x = data['text']
y = data['class']
cv = CountVectorizer()
x_train, x_test, y_train, y_test = train_test_split(x, y, stratify = y,test_size = 0.1, random_state=42)
x_train = cv.fit_transform(x_train).toarray()
x_test = cv.transform(x_test).toarray()
from sklearn.naive_bayes import BernoulliNB
model = BernoulliNB()
model.fit(x_test, y_test)
# score test data test
model.score(x_test, y_test)
# score for data training
model.score(x_train,y_train)
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import confusion_matrix, accuracy_score
data = pd.read_csv("C:\\Users\\fkhas\\Documents\\Projects\\Twitter\\SA\\analisissentimen\\Datasets\\Sentiment Idul Fitri.csv")
data.head(10)
def preprocess_data(data):
# Remove package name as it's not relevant
data = data.drop('score', axis=1)
# Convert text to lowercase
data['text'] = data['text'].str.strip().str.lower()
return data
data = preprocess_data(data)
# Split into training and testing data
x = data['text']
y = data['class']
cv = CountVectorizer()
x_train, x_test, y_train, y_test = train_test_split(x, y, stratify = y, test_size = 0.10, random_state=42)
x_train = cv.fit_transform(x_train).toarray()
x_test = cv.transform(x_test).toarray()
from sklearn.naive_bayes import BernoulliNB
model = BernoulliNB()
model.fit(x_test, y_test)
# score test data test
model.score(x_test, y_test)
# score for data training
model.score(x_train,y_train)
from jcopml.plot import plot_classification_report
plot_classification_report(x_train,y_tran,x_test,y_test,model, report = True)
from jcopml.plot import plot_classification_report
plot_classification_report(x_train,y_train,x_test,y_test,model, report = True)
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import confusion_matrix, accuracy_score
data = pd.read_csv("C:\\Users\\fkhas\\Documents\\Projects\\Twitter\\SA\\analisissentimen\\Datasets\\Sentiment Idul Fitri.csv")
data.head(10)
def preprocess_data(data):
# Remove package name as it's not relevant
data = data.drop('score', axis=1)
# Convert text to lowercase
data['text'] = data['text'].str.strip().str.lower()
return data
data = preprocess_data(data)
# Split into training and testing data
x = data['text']
y = data['class']
cv = CountVectorizer()
x_train, x_test, y_train, y_test = train_test_split(x, y, stratify = y, test_size = 0.10, random_state=42)
x_train = cv.fit_transform(x_train).toarray()
x_test = cv.transform(x_test).toarray()
from sklearn.naive_bayes import BernoulliNB
model = BernoulliNB()
model.fit(x_train, y_train)
# score test data test
model.score(x_test, y_test)
# score for data training
model.score(x_train,y_train)
from jcopml.plot import plot_classification_report
plot_classification_report(x_train,y_train,x_test,y_test,model, report = True)
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import confusion_matrix, accuracy_score
data = pd.read_csv("C:\\Users\\fkhas\\Documents\\Projects\\Twitter\\SA\\analisissentimen\\Datasets\\Sentiment Idul Fitri.csv")
data.head(10)
def preprocess_data(data):
# Remove package name as it's not relevant
data = data.drop('score', axis=1)
# Convert text to lowercase
data['text'] = data['text'].str.strip().str.lower()
return data
data = preprocess_data(data)
# Split into training and testing data
x = data['text']
y = data['class']
cv = TfidfVectorizer()
x_train, x_test, y_train, y_test = train_test_split(x, y, stratify = y, test_size = 0.10, random_state=42)
x_train = cv.fit_transform(x_train).toarray()
x_test = cv.transform(x_test).toarray()
from sklearn.naive_bayes import BernoulliNB
model = BernoulliNB()
model.fit(x_train, y_train)
# score test data test
model.score(x_test, y_test)
# score for data training
model.score(x_train,y_train)
from jcopml.plot import plot_classification_report
plot_classification_report(x_train,y_train,x_test,y_test,model, report = True)
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
cv = TfidfVectorizer()
x_train, x_test, y_train, y_test = train_test_split(x, y, stratify = y, test_size = 0.10, random_state=42)
x_train = cv.fit_transform(x_train).toarray()
x_test = cv.transform(x_test).toarray()
from sklearn.naive_bayes import BernoulliNB
model = BernoulliNB()
model.fit(x_train, y_train)
# score test data test
model.score(x_test, y_test)
# score for data training
model.score(x_train,y_train)
from jcopml.plot import plot_classification_report
plot_classification_report(x_train,y_train,x_test,y_test,model, report = True)
help(TfidfVectorizer)
reticulate::repl_python()
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import confusion_matrix, accuracy_score
data = pd.read_csv("C:\\Users\\fkhas\\Documents\\Projects\\Twitter\\SA\\analisissentimen\\Datasets\\Sentiment Idul Fitri.csv")
data.head(10)
def preprocess_data(data):
# Remove package name as it's not relevant
data = data.drop('score', axis=1)
# Convert text to lowercase
data['text'] = data['text'].str.strip().str.lower()
return data
data = preprocess_data(data)
# Split into training and testing data
x = data['text']
y = data['class']
cv = CountVectorizer()
x_train, x_test, y_train, y_test = train_test_split(x, y, stratify = y, test_size = 0.10, random_state=42)
x_train = cv.fit_transform(x_train).toarray()
x_test = cv.transform(x_test).toarray()
from sklearn.naive_bayes import BernoulliNB
model = BernoulliNB()
model.fit(x_train, y_train)
# score test data test
model.score(x_test, y_test)
# score for data training
model.score(x_train,y_train)
from jcopml.plot import plot_classification_report
plot_classification_report(x_train,y_train,x_test,y_test,model, report = True)
help(Tfidfvectorize)
from sklearn.feature_extraction.text import CountVectorizer, Tfidfvectorizer
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizerectorizer
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
help(Tfidfvectorzier)
help(TfidfVectorizer)
View(rm.stopword)
View(df)
View(scores.sentiment)
View(scores.sentiment)
View(scores.sentiment)
library(readr)
Sentiment_Total <- read_csv("Datasets/Sentiment Total.csv")
View(Sentiment_Total)
library(readxl)
testduplicate <- read_excel("~/testduplicate.xlsx")
View(testduplicate)
library(dplyr)
# remove duplicate and select single column for only text
testduplicate.df = testduplicate %>% distinct(Nama, .keep_all = FALSE)
View(testduplicate)
# remove duplicate and select single column for only text
testduplicate.df = testduplicate %>% distinct(text, .keep_all = FALSE)
# remove duplicate and select single column for only text
testduplicate.df = testduplicate %>% distinct(Nama, Kelas, .keep_all = FALSE)
View(testduplicate.df)
View(tdm)
tdm[["dimnames"]][["Terms"]]
citation("katadasaR")
reticulate::repl_python()
import pandas as pd
?VCorpus
library(readr)
Data_Idul_Fitri <- read_csv("Datasets/Data Idul Fitri.csv")
View(Data_Idul_Fitri)
library(readr)
Data_Shalat_Id <- read_csv("Datasets/Data Shalat Id.csv")
View(Data_Shalat_Id)
library(readr)
Data_Silaturahmi <- read_csv("Datasets/Data Silaturahmi.csv")
View(Data_Silaturahmi)
library(readr)
Data_Takbiran <- read_csv("Datasets/Data Takbiran.csv")
View(Data_Takbiran)
library(readr)
Data_Ziarah <- read_csv("Datasets/Data Ziarah.csv")
View(Data_Ziarah)
length(Data_Idul_Fitri)
View(booster)
View(Data_Idul_Fitri)
View(tdm)
tdm[["dimnames"]][["Terms"]]
tdm[["dimnames"]][["Terms"]]
View(tweet.corpus)
tweet.corpus[["1"]]
tweet.corpus[["1"]][["content"]]
tweet.corpus[["91"]][["content"]]
rm(list=ls())
# Load Data from Computer
tweets.df = read.csv(file = '~/Projects/Twitter/SA/analisissentimen/Datasets/Data Idul Fitri.csv',
header = TRUE,
sep = ',')
# ===== DATA CLEANSING
# Work with Corpus
tweet.corpus = VCorpus(VectorSource(tweets.df$text))
inspect(tweet.corpus[[1]])
# load needed packages
library(dplyr)
library(tidyr)
library(tidytext)
library(tm)
library(dplyr)
library(stringr)
library(wordcloud)
library(ggplot2)
library(rtweet)
# ===== DATA CLEANSING
# Work with Corpus
tweet.corpus = VCorpus(VectorSource(tweets.df$text))
inspect(tweet.corpus[[1]])
View(tweets.df)
source(file = '~/Projects/Twitter/SA/analisissentimen/Helpers/Function Helper/Cleansing.R')
# TRANSFORM TO LOWER CASE
tweet.corpus = tm_map(tweet.corpus, content_transformer(tolower))
# FILTERING - CUSTOM CLEANSING FUNCTIONS
View(tweet.corpus)
tweet.corpus[["5"]][["content"]]
tweet.corpus[["8"]][["content"]]
View(tweets.df)
tweet.corpus = tm_map(tweet.corpus, content_transformer(removeURL))
tweet.corpus = tm_map(tweet.corpus, content_transformer(unescapeHTML))
tweet.corpus = tm_map(tweet.corpus, content_transformer(removeMention))
tweet.corpus = tm_map(tweet.corpus, content_transformer(removeCarriage))
tweet.corpus = tm_map(tweet.corpus, content_transformer(removeEmoticon))
tweet.corpus = tm_map(tweet.corpus, content_transformer(removeInvoice))
# Remove additional symbols to white space
tweet.corpus = tm_map(tweet.corpus, toSpace, "[[:punct:]]") # punctuation
tweet.corpus = tm_map(tweet.corpus, toSpace, "[[:digit:]]") # numbers
# Eliminate extra white spaces
tweet.corpus = tm_map(tweet.corpus, stripWhitespace)
View(tweet.corpus)
tweet.corpus[["8"]][["content"]]
View(tweets.df)
# Eliminate extra white spaces
tweet.corpus = tm_map(tweet.corpus, stripWhitespace)
# Check the final result
inspect(tweet.corpus[[1]])
# SPELLING NORMALIZATION
spell.lex = read.csv(file = '~/Projects/Twitter/SA/analisissentimen/Helpers/Data Helper/colloquial-indonesian-lexicon.txt',
header = TRUE,
sep = ',',
stringsAsFactors = FALSE)
# Import external function
source(file = '~/Projects/Twitter/SA/analisissentimen/Helpers/Function Helper/Cleansing.R')
tweet.corpus = tm_map(tweet.corpus, spell.correction, spell.lex)
# STEMMING WORDS
# Import external function
source(file = '~/Projects/Twitter/SA/analisissentimen/Helpers/Function Helper/Cleansing.R')
tweet.corpus = tm_map(tweet.corpus, content_transformer(stemming))
View(tweet.corpus)
tweet.corpus[["35"]][["content"]]
tweet.corpus[["36"]][["content"]]
# ===== LEXICON-BASED SENTIMENT SCORING
pos = readLines('~/Projects/Twitter/SA/analisissentimen/Helpers/Data Helper/s-pos.txt')
neg = readLines('~/Projects/Twitter/SA/analisissentimen/Helpers/Data Helper/s-neg.txt')
df.tweet = data.frame(text = sapply(tweet.corpus, as.character),
stringsAsFactors = FALSE)
View(df.tweet)
# Negation Handling
negasi = scan('~/Projects/Twitter/SA/analisissentimen/Helpers/Data Helper/negatingword.txt',
what = 'character')
senti = read.csv('~/Projects/Twitter/SA/analisissentimen/Helpers/Data Helper/sentiwords_id.txt',
sep = ':',
header = FALSE) %>%
mutate(words = as.character(V1),
score = as.numeric(V2)) %>%
select(c('words','score'))
booster = read.csv('~/Projects/Twitter/SA/analisissentimen/Helpers/Data Helper/boosterwords_id.txt',
sep = ":",
header = FALSE) %>%
mutate(words = as.character(V1),
score = as.numeric(V2)) %>%
select(c('words','score'))
# load needed packages
library(dplyr)
library(tidyr)
library(tidytext)
library(tm)
library(dplyr)
library(stringr)
library(wordcloud)
library(ggplot2)
library(rtweet)
# Negation Handling
negasi = scan('~/Projects/Twitter/SA/analisissentimen/Helpers/Data Helper/negatingword.txt',
what = 'character')
senti = read.csv('~/Projects/Twitter/SA/analisissentimen/Helpers/Data Helper/sentiwords_id.txt',
sep = ':',
header = FALSE) %>%
mutate(words = as.character(V1),
score = as.numeric(V2)) %>%
select(c('words','score'))
booster = read.csv('~/Projects/Twitter/SA/analisissentimen/Helpers/Data Helper/boosterwords_id.txt',
sep = ":",
header = FALSE) %>%
mutate(words = as.character(V1),
score = as.numeric(V2)) %>%
select(c('words','score'))
# Import external function
source(file = '~/Projects/Twitter/SA/analisissentimen/Helpers/Function Helper/Lexicon-Based Scoring Analysis.R')
results = scores.sentiment(df.tweet$text, senti, negasi)
# Import external function
source(file = '~/Projects/Twitter/SA/analisissentimen/Helpers/Function Helper/Lexicon-Based Scoring Analysis.R')
results = scores.sentiment(df.tweet$text, senti, negasi)
set.seed(2211)
random.tweet = sample(x = df.tweet$text,
size = 10)
head(scores.sentiment(random.tweet, senti, negasi),5)
# Convert score to sentiment classes
results$class = as.factor(ifelse(results$score < 0, 'Negative',
ifelse(results$score == 0, 'Neutral','Positive')))
View(results)
# load needed packages
library(dplyr)
library(tidyr)
library(tidytext)
library(tm)
library(dplyr)
library(stringr)
library(wordcloud)
library(ggplot2)
library(rtweet)
?tm_map
?content_transformer
library(readr)
Sentiment_Takbiran <- read_csv("Datasets/Sentiment Takbiran.csv")
View(Sentiment_Takbiran)
tail(Sentiment_Takbiran)
tail(Sentiment_Takbiran)
library(ggplot2)
?ggplot
